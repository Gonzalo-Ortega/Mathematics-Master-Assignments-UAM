\section{Optimal transport}
The main result of optimal transport theory is the solution of Kantorovich's problem for general costs: the existence of an optimal transport plan. Lets start by introducing Monge's and Kantorovich's problems, observing its main key difference. For that, we shall fist define a way to compare probability measures from two different spaces. We will denote the set of probability measures over a space X by $ \p(X) $, and the class of Borel-measurable sets by $ \B(X) $.

\begin{definition}[Push-forward measure]
    Let $ T: X \to Y $ be a Borel map, and $ \mu \in \p(X)$. Let $ A \in \B $. The {\it push-forward measure} $ \T\mu \in \p(Y) $ is defined as
    $$
        \T\mu(A) := \mu (T^{-1}(A)).
    $$
\end{definition}

Now we can introduce transport maps, as functions witch transform one probability measure into an other.

\begin{definition}[Transport map]
    Given $ \mu \in \p(X) $ and $ \nu \in \p(Y) $, a {\it transport map from $\mu$ to $\nu$} is a Borel map $ T: X \to Y $ that satisfies $ \T\mu = \nu$.
\end{definition}


\begin{definition}[Transport plan]
    Let $\pi_X : (X \times Y) \to X $ and $\pi_Y : (X \times Y) \to Y$ such that for every $(x, y) \in (X, Y) $, $\pi_X(x, y) = x$ and $ \pi_Y(x, y) = y $. A {\it transport plan between $\mu$ and $\nu$} is a probability measure $ \gamma \in \p(X \times Y) $ where
    $$
        (\pi_X)_\# \gamma = \mu \text{ and } (\pi_Y)_\# \gamma = \nu.
    $$
    The set of all couplings between $ \mu $ and $\nu$ is denoted $\Gamma(\mu, \nu)$.
\end{definition}

While the set of transport maps between two given probability measures might be empty, transport plans are a more flexible generalization of them allowing to modulate one measure into the other. In probability theory, transport plans are named {\it couplings}, and $\Gamma(\mu, \nu)$ is the collection of all probability measures in $ X \times Y $ with {\it marginals} $ \mu $ and $ \nu $ \cite{class}.

Given this definitions, we can introduce Monge and Kantorovich problems, $ C_M(\mu, \nu) $ and $ C_K(\mu, \nu) $ respectively, as follows.

\begin{definition}[Transport problems]
    Fix $ \mu \in \p(X)$, $\nu \in \p(Y)$ and consider a lower semicontinous map $ c: X \times Y \to [0, \infty] $. Then
\begin{align*}
    C_M(\mu, \nu) &:= \inf \left\{\int_X c(x, T(x)) d\mu(x) : \T\mu = \nu \right\}, \\
    C_K(\mu, \nu) &:= \inf \left\{\int_{X \times Y} c(x, y) d\gamma(x,y) : \gamma \in \Gamma(\mu, \nu) \ \right\}.
\end{align*}
\end{definition}

Next theorem asserts that it actually exists a minimizing transport plan that minimizes Kantorovich problem. This will prove useful to verify that Wasserstein distance exists and it is a well defined metric.

\begin{theorem}
    Let $ c: X \times Y \to [0, \infty] $ be lower semicontinous, and let $ \mu \in \p(X) $ and $ \nu \in \p(Y) $. Then there exists a coupling $ \bar \gamma \in \Gamma(\mu, \nu) $ that verifies
    $$
    C_K(\mu, \nu) = \int_{X \times Y} c(x, y) d \bar \gamma(x,y).
    $$
\end{theorem}
\begin{proof}
    (to do)
\end{proof}

\begin{example}[Mean and variance in $ \mathbb R $]
    
\end{example}

\begin{definition}[Probability measures with finite $p$-moment]
    Let $ (X, d) $ be a locally compact and separable, metric space. Let $ 1 \leq p < \infty $. The {\it set of probability measures with finite $p$-moment} is defined As
    $$
        \p_p (X) := \left\{ \sigma \in \p (X) : \int_X d(x, x_0)^p d \mu (x) < \infty \text{ for some } x_0 \in X \right\}.
    $$
\end{definition}

\begin{proposition}
    The definition of $ \p_p (X) $ is independent of the base point $ x_0 $
\end{proposition}
\begin{proof}
    (to do)
\end{proof}

\begin{definition}[$p$-Wasserstein distance]
    Given $ u, v \in \p_p (X) $, the {\it $p$-Wasserstein distance} is defined as
    $$
        W_p(u, v) := \left( \inf_{\gamma \in \Gamma(u, v)} \int_{X \times X} d(x,y)^p d\gamma(x, y)\right)^{\frac{1}{p}}.
    $$
\end{definition}

Finally, we will proof that the $p$-Wasserstein distance is a metric in the space of Probability measures with finite $p$-moment. To check the triangle inequality, we will make use of the following auxiliary theorem of probability theory. Let $ \mathbf X $ denote $ X_1  \times \cdots \times X_n $ for some $ n \in \N $.

\begin{theorem}[Disintegration] \label{thm:disintegration}
    Let $ \mathbf X, X $ be Radon separable metric spaces, $ \mathbf \mu \in \p(\mathbf X) $, let $ \pi: \mathbb X \to X $ be a Borel map and let $ \nu = \pi_\#\mu \in \p(X) $. Then there exists a $\nu$-a.e. uniquely determined Borel family of probability measures $ \{\mu_x\}_{x \in X} \subset \p(\mathbf X) $ such that
    $$
        \mu_x(\mathbf X \setminus \pi^{-1}(x)) = 0 \text{ for } \nu \text{-a. } x \in X
    $$
    and
    $$
        \int_{\mathbf X} f(\mathbf x) \, d \mathbf \mu( \mathbf x) = \int_X \left( \int_{\pi^{-1}(x)} f(\mathbf x) \, d\mu_x( \mathbf x) \right) d\nu(x).
    $$
\end{theorem}

The proof of this theorem goes out of the reach of this thesis, the interested reader can find one proof at \cite{ambrosio}[Theorem 5.3.1]. The disintegration theorem needs $ X $ to be a Radon space, that is, every finite Borel measure is a Radon measure. With a Radon measure being a measure that is finite on all compact sets, outer regular on all Borel sets, and inner regular on open sets.

It is also possible to prove the triangle inequality in a more elementary manner without the use of the disintegration theorem as seen in \cite{elementary}. This ables to omit the assumption of the underlying space been Radon, but obtaining an obscurer proof in exchange. For the aim of this thesis, will be confortable with the requirements of the disintegration theorem and we present a proof following the steps made in \cite{Figalli}[Theorem 3.1.5].

\begin{proposition}
    $W_p$ is a distance on the space $ \p_p(X) $.
\end{proposition}

\begin{proof}
    To prove the triangle inequality, let $ \mu_1, \mu_2, \mu_3 \in \p_p(X) $ and let $ \gamma_{12} \in \Gamma(\mu_1, \mu_2) $ and $ \gamma_{23} \in \Gamma(\mu_2, \mu_3) $ be optimal couplings. Let $ \tilde \gamma \in \p(X \times X \times X) $. Using Theorem \ref{thm:disintegration} we have
    \begin{align*}
        &\int_{X \times X \times X} \phi(x_1, x_2) d \tilde \gamma (x_1, x_2, x_3) \\
        = &\int_{X \times X} \left(\int_X \phi(x_1, x_2) \gamma_{12,x_2} (dx_1)  d \gamma_{23}(x_3) \right) d \mu_2(x_2 ) \\
        = &\int_{X \times X} \phi(x_1, x_2) \gamma_{12,x_2} (dx_1) \left(\int_X d \gamma_{23}(x_3)\right) d \mu_2(x_2 ) \\
        = &\int_{X \times X} \phi(x_1, x_2) \gamma_{12}(x_1, x_2).
    \end{align*}
    In the same way
    \begin{align*}
        \int_{X \times X \times X} \phi(x_2, x_3) d \tilde \gamma (x_1, x_2, x_3) = \int_{X \times X} \phi(x_2, x_3) \gamma_{23}(x_2, x_3).
    \end{align*}
    Therefore, note that we also have
    \begin{align*}
        &\int_{X \times X \times X} \psi(x_1) d \tilde \gamma (x_1, x_2, x_3)  
        = \int_{X \times X} \psi(x_1) d \gamma_{12} (x_1, x_2)
        = \int_{X} \psi(x_1) d \gamma_1 (x_1)
    \end{align*}
    and
    \begin{align*}
        &\int_{X \times X \times X} \psi(x_3) d \tilde \gamma (x_1, x_2, x_3)  
        = \int_{X} \psi(x_3) d \gamma_3 (x_3).
    \end{align*}
    This two equations imply that
    \begin{align*}
        &\int_{X \times X \times X} \phi(x_1 x_3) d \tilde \gamma (x_1, x_2, x_3)  
        = \int_{X} \phi(x_1, x_3) d \tilde \gamma (x_1, x_2, x_3).
    \end{align*}
    Then, if we set $ \bar \gamma_{13} := \int_X \tilde \gamma (x_1, x_2, x_3) $, we have that $ \bar \gamma_{13} \in \Gamma(\mu_1, \mu_3)$.
    Finally, using the triangle inequality of the Lebesgue space $ L^p(X \times X \times X, \tilde \gamma) $ we have
    \begin{align*}
        W_p(\mu_1, \mu_3) &\leq \left(\int_{X \times X} d(x_1, x_3)^p d \bar \gamma_{13}(x_1, x_3)\right)^\frac{1}{p} \\
        &= \left(\int_{X \times X} d(x_1, x_3)^p d \tilde \gamma_{13}(x_1, x_2 x_3)\right)^\frac{1}{p} \\
        &= ||d(x_1, x_3)||_{L^p(\tilde \gamma)} \leq ||d(x_1, x_2) + d(x_2, x_3)||_{L^p(\tilde \gamma)} \\
        &\leq ||d(x_1, x_2)||_{L^p(\tilde \gamma)} + ||d(x_2, x_3)||_{L^p(\tilde \gamma)} \\
        &\leq ||d(x_1, x_2)||_{L^p(\gamma{12})} + ||d(x_2, x_3)||_{L^p(\gamma{23})} \\
        &= W_p(\mu_1, \mu_2) + W_p(\mu_2, \mu_3).
    \end{align*}
\end{proof}